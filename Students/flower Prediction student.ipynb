{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10-TPOxQvVJao1-0i_8giQ2M28tUkpev_","timestamp":1692032325279}],"authorship_tag":"ABX9TyNi3qTJfZKgyPV2aOK7jPMw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Flower Prediction**"],"metadata":{"id":"Gzopn5_xniUO"}},{"cell_type":"markdown","source":["import libraries"],"metadata":{"id":"J8YLMQL0_S_F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0Yg4VtLoSth"},"outputs":[],"source":["import None"]},{"cell_type":"code","source":["from tensorflow import None\n","from tensorflow.keras.preprocessing.image import None\n","from tensorflow.keras.models import None\n","from tensorflow.keras import None\n","from tensorflow.keras.layers import None"],"metadata":{"id":"uhZkiiNNoeuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Getting dataset\n","\n","\n"],"metadata":{"id":"WEJheZlxDg0H"}},{"cell_type":"code","source":["import pathlib\n","\n","dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n","data_dir = pathlib.Path(data_dir).with_suffix('')"],"metadata":{"id":"m-X4zuCEomfR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finding length or count of images in our dataset."],"metadata":{"id":"hIbBBI-3Djy2"}},{"cell_type":"code","source":["image_count = None (list(data_dir.glob('*/*.jpg')))\n","print(\"Image Count = \",image_count)"],"metadata":{"id":"2vxTo1rXo1qX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking some of the dataset images how the look."],"metadata":{"id":"kCVQzU2xDswx"}},{"cell_type":"code","source":["roses = list(data_dir.glob('roses/*'))\n","PIL.Image.None (str(roses[0]))"],"metadata":{"id":"QVJd1TxXpEkp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Change the index value of the class to get more images of the flower of the class.**\n","\n","*   Rose=0-641\n","*   Daisy=0-633\n","*   Dandelion=0-898\n","*   Tulips=0-799\n","*   Sunflowers=0-699\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"aQnFlHdrArKc"}},{"cell_type":"code","source":["Roses=len(list(data_dir.glob('roses/*')))\n","Roses"],"metadata":{"id":"7ITPfyyTD2fw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PIL.Image.None (str(roses[1]))"],"metadata":{"id":"9IduOFPgpGp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tulips = list(data_dir.glob('tulips/*'))\n","PIL.Image.None (str(tulips[0]))"],"metadata":{"id":"7WjyxgWMpIk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PIL.Image.None (str(tulips[2]))"],"metadata":{"id":"cCRVr5g0pKN9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Deciding batch of the dataset and deciding its height and width\n","\n"],"metadata":{"id":"0DqIp-I3EU4n"}},{"cell_type":"code","source":["batch_size = None\n","img_height = None\n","img_width = None"],"metadata":{"id":"rHfid2rApLwn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Spiliting data for training data"],"metadata":{"id":"antUw-w1EhRm"}},{"cell_type":"code","source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=None,\n","  subset=None,\n","  seed=None,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"3ebbNyqlpSLH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Spiliting data for testing data"],"metadata":{"id":"vPmvW5--Eou7"}},{"cell_type":"code","source":["val_ds = tf.keras.utils.image_dataset_from_directory(\n","  data_dir,\n","  validation_split=None,\n","  subset=None,\n","  seed=None,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"metadata":{"id":"GHZ2NvH3pUFP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking types of classes do we have in the dataset"],"metadata":{"id":"TiSzzLMJEs7c"}},{"cell_type":"code","source":["class_names = train_ds.None\n","print(class_names)"],"metadata":{"id":"j6VFtXWupV4w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Showing some images randomly ,providing name manually\n","\n","\n"],"metadata":{"id":"cvmUsOKSEztS"}},{"cell_type":"code","source":["plt.figure(figsize=(None))\n","for images, labels in train_ds.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")"],"metadata":{"id":"2SF2jQBQpXgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image_batch, labels_batch in train_ds:\n","  print(\"Image Batch = \",image_batch.shape)\n","  print(\"Labels = \",labels_batch.shape)\n","  break"],"metadata":{"id":"807lGMNmpZmw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tuning the train and validation dataset"],"metadata":{"id":"FgEnyHxYE_xR"}},{"cell_type":"code","source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().shuffle(None).prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"4fdql9PqpckA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalizing the data"],"metadata":{"id":"972VwAUvFFBM"}},{"cell_type":"code","source":["normalization_layer = layers.Rescaling(None)"],"metadata":{"id":"CcFHJVB9pf4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","image_batch, labels_batch = next(iter(normalized_ds))\n","first_image = image_batch[0]\n","# Notice the pixel values are now in `[0,1]`.\n","print(np.min(first_image), np.max(first_image))"],"metadata":{"id":"8UaoKqncpjA9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating model for training data\n","\n","\n"],"metadata":{"id":"jlsSLHY1FL-g"}},{"cell_type":"code","source":["num_classes = len(class_names)\n","\n","model = Sequential([\n","  layers.Rescaling(None, input_shape=(img_height, img_width, 3)),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Flatten(),\n","  layers.Dense(None, activation='relu'),\n","  layers.Dense(num_classes)\n","])"],"metadata":{"id":"aUDk2oPCpki2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating summary"],"metadata":{"id":"TQdzzMDJFR0b"}},{"cell_type":"code","source":["model.compile(optimizer='None',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['None'])\n","model.summary()"],"metadata":{"id":"96zaIvR3poFH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training the model"],"metadata":{"id":"F3jENh0xFU0h"}},{"cell_type":"code","source":["epochs=None\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"pdxEiARPppty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ploting graph according to the above training"],"metadata":{"id":"_r_XGDrCFZBv"}},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"metadata":{"id":"M6S2caG8p0Qq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Image formating"],"metadata":{"id":"cfCBvvwDFf94"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","  [\n","    layers.RandomFlip(\"horizontal\",\n","                      input_shape=(img_height,\n","                                  img_width,\n","                                  3)),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1),\n","  ]\n",")"],"metadata":{"id":"WKYB3tZJp2cC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(None))\n","for images, _ in train_ds.take(1):\n","  for i in range(9):\n","    augmented_images = data_augmentation(images)\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"],"metadata":{"id":"0Uhg0x3Qp6B_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Repeating steps for validation data\n","\n","\n"],"metadata":{"id":"TSAPt_GEFqa4"}},{"cell_type":"code","source":["model = Sequential([\n","  data_augmentation,\n","  layers.Rescaling(None),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Conv2D(None, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","  layers.Dropout(0.2),\n","  layers.Flatten(),\n","  layers.Dense(None, activation='relu'),\n","  layers.Dense(num_classes, name=\"outputs\")\n","])"],"metadata":{"id":"ksqQ9aiAp7hh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='None',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['None'])\n","model.summary()"],"metadata":{"id":"6AS0kDcyp9jX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = None\n","history = model.fit(\n","  train_ds,\n","  validation_data=val_ds,\n","  epochs=epochs\n",")"],"metadata":{"id":"mahRls1IqAIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()\n"],"metadata":{"id":"kr2oG2IVqGYF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testing the model"],"metadata":{"id":"KVMEdGqFFxPE"}},{"cell_type":"code","source":["sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n","sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n","\n","img = tf.keras.utils.load_img(\n","    sunflower_path, target_size=(img_height, img_width)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(None)\n","\n","img=mpimg.imread(sunflower_path)\n","ingplot=plt.imshow(img)\n","plt.show()\n","\n"],"metadata":{"id":"W1D60HNcqIqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the model.\n","converter = tf.lite.TFLiteConverter.from_keras_model(None)\n","tflite_model = converter.convert()\n","\n","# Save the model.\n","with open('model.tflite', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"ltXKXZjdqMFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TF_MODEL_FILE_PATH = 'model.tflite' # The default path to the saved TensorFlow Lite model\n","\n","interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)"],"metadata":{"id":"1PP9_fuhqOUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["interpreter.get_signature_list()"],"metadata":{"id":"P2Mv17lYqSKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classify_lite = interpreter.get_signature_runner('serving_default')\n","classify_lite"],"metadata":{"id":"8EsmL9g5qTrd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Independent Testing"],"metadata":{"id":"fNYRFmmWF2Wr"}},{"cell_type":"code","source":["flower_path = \"None\"  # provide path\n","\n","img = tf.keras.utils.load_img(\n","    flower_path, target_size=(img_height, img_width)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",")\n","\n","img=mpimg.imread(flower_path)\n","ingplot=plt.imshow(img)\n","plt.show()"],"metadata":{"id":"YAkCX4CG9AZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w_Yz4sHi9A0l"},"execution_count":null,"outputs":[]}]}